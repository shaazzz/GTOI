آشنایی با الگوریتم ها و پیچیدگی
=================================

امروزه کامپیوتر ها بسیار سریع هستند، اما هیچ کامپیوتری دستورات را در لحظه اجرا نمی کند.
مقدار بسیار کوچکی از زمان طول می کشد که کامپیوتر یک دستور را اجرا کند. برای مثال کامپیوتر
های امروز در فرکانس حدود سه گیگاهرتز کار می کنند که یعنی یک زیر دستور العمل را در زمان
حدود سه دهم نانو ثانیه انجام می دهند که این یعنی هر دستور العمل در حدود چند نانو ثانیه
زمان می برد.

با این حال کار نوشتن برنامه ای که ساعت ها، یا حتی سال ها زمان ببرد، اصلا کار سختی
نیست. حتی ممکن است خودتان به آن برخورده باشید. مثلا در پردازش فیلم یا شبیه سازی های
فیزیکی ممکن است ساعت ها کامپیوتر خود را روشن گذاشته باشید تا پاسخ را دریافت کنید.

به همین دلیل در مسابقات برنامه نویسی محدودیت زمانی برای اجرای برنامه شما وجود دارد
و برنامه شما باید در زمانی حدود ۱ تا ۵ ثانیه
(بسته به مساله)
اجرا شود. به همین دلیل در هنگام طراحی الگوریتم ها محاسبه می کنیم که آیا راه ما
با توجه به شرایط ورودی در زمان خواسته شده اجرا می شود یا خیر و اگر اجرا می شد شروع
به پیاده سازی آن می کنیم.

Introduction to Algorithms and Complexity
=========================================

Today, computers are very fast, but no computer executes instructions instantly.
It takes a very small amount of time for a computer to execute an instruction. For example, today's computers
operate at a frequency of about three gigahertz, which means they perform a sub-instruction in about
three-tenths of a nanosecond, implying that each instruction takes a few nanoseconds.

However, writing a program that takes hours, or even years, is not difficult at all.
You might have even encountered it yourself. For instance, in video processing or physical simulations,
you might have left your computer on for hours to get a result.

For this reason, programming contests have a time limit for your program's execution,
and your program must run within approximately 1 to 5 seconds
(depending on the problem).
Therefore, when designing algorithms, we calculate whether our approach
will execute within the required time given the input conditions, and if it does, we proceed
to implement it.

تحلیل پیچیدگی
-------------------
سخت است که زمان اجرای یک برنامه را به طور دقیق حساب کنیم. برای مثال دستور


.. code-block:: cpp
  
  a[x] += a[y];

را در نظر بگیرید. این دستور چند عمل در سی پی یو است؟ پاسخ به این سوال بسیار سخت و نیازمند
شناخت دقیق کامپایلر و سی پی یو است. حتی ممکن است پاسخ این سوال بسته به نوع سی پی یو یا
کامپایلر یا درجه بهینه سازی کامپایلر یا مکان قرار گیری این دستور در کد فرق کند. برای مثال
خواندن y از حافظه، جمع x با a و خواندن خانه به دست آمده از حافظه یا جمع
مقدار a[x] و a[y] می تواند یک یا چند دستور العمل در سی پی یو باشد.

حتی اگر می دانستیم که برنامه ما از چند دستور العمل تشکیل شده، باز برای تخمین زمان اجرای
برنامه کافی نبود. برای مثال دستور باقیمانده و دستور شیفت بیتی هر دو یک دستور العمل
هستند اما باقیمانده بسیار بیشتر از شیفت بیتی طول می کشد.

بنابراین از محاسبه زمان دقیق اجرای کد صرف نظر می کنیم و تنها به این اکتفا می کنیم که
دستورات سی پی یو مانند خواندن از آرایه یا جمع دو عدد، مقدار ثابتی از زمان طول می کشند.
به همین صورت، دقت اندازه گیری ما در حد یک ضریب پایین می آید. برای مثال این کد را در نظر بگیرید


.. code-block:: cpp
  
  for (int i = 0; i < n; i++) {
    for (int j = 0; j < n; j++) {
      swap(a[i],a[j]);
    }
  }

ما نمی دانیم که تابع سوپ یا عمل مقایسه یا عمل پلاس پلاس هر کدام چند واحد زمانی طول می کشند
اما می دانیم که هر کدام مقدار ثابتی از زمان طول می کشند. پس می توان گفت که زمان اجرای این کد
:math:`kn^2`
است که k یک ضریب ثابت با واحد ثانیه است.
در عموم موارد مقدار k برای ما اهمیتی ندارد و از آن چشم پوشی می کنیم.

Complexity Analysis
-------------------
It is difficult to precisely calculate the execution time of a program. For example, consider the instruction:

.. code-block:: cpp
  
  a[x] += a[y];

How many CPU operations is this instruction? The answer to this question is very difficult and requires
a detailed understanding of the compiler and CPU. The answer to this question might even vary depending on the CPU type,
compiler, compiler optimization level, or the location of this instruction in the code. For example,
reading `y` from memory, adding `x` to `a` and reading the resulting memory location, or summing
the values of `a[x]` and `a[y]` can be one or more CPU instructions.

Even if we knew how many instructions our program consisted of, it would still not be enough to estimate the
program's execution time. For example, the modulo operator and the bit shift operator are both
single instructions, but modulo takes significantly longer than a bit shift.

Therefore, we forgo calculating the exact execution time of the code and only assume that
CPU instructions, such as reading from an array or adding two numbers, take a constant amount of time.
Similarly, our measurement precision drops to a constant factor. For example, consider this code:

.. code-block:: cpp
  
  for (int i = 0; i < n; i++) {
    for (int j = 0; j < n; j++) {
      swap(a[i],a[j]);
    }
  }

We don't know how many time units the `swap` function, comparison operation, or increment operation takes,
but we do know that each takes a constant amount of time. So, it can be said that the execution time of this code
is :math:`kn^2`, where k is a constant factor with units of seconds.
In most cases, the value of k is not important to us, and we disregard it.

نماد ها
~~~~~~~~~~
چون می توانیم از ضریب چشم پوشی کنیم، تعریف نماد های زیر خالی از لطف نیست:

- نماد
  :math:`f(n) = O(g(n))`:
  این نماد به این این معنی است که ضریبی مانند k وجود دارد به طوری که
  :math:`f(n) \le kg(n)`
  به ازای تمامی n های بزرگ برقرار باشد.
  این نماد به صورت اِف اِن از او یِ جیِ اِن است خوانده می شود.
- نماد
  :math:`f(n) = \Omega (g(n))`:
  اگر و تنها اگر
  :math:`g(n) = O(f(n))`
  بر قرار باشد برقرار است و می خوانیم
  اِف اِن از اُمِگا یِ جیِ اِن است
- نماد
  :math:`f(n) = \theta (g(n))`:
  اگر و تنها اگر
  :math:`f(n) = O(g(n))` و :math:`f(n) = \Omega (g(n))`
  بر قرار باشد برقرار است و می خوانیم
  اِف اِن از تِتا یِ جیِ اِن است
  
به این نماد ها می توانید به چشم علامت های کوچکتر مساوی، بزرگتر مساوی و مساوی نگاه کنید.
مثال های زیر می تواند به درک بهتر این علامت ها کمک کند.

.. math:: 1000n = O(0.00001n)
.. math:: 1000n = \Omega(0.00001n)
.. math:: 1000n = \theta(0.00001n)
.. math:: 1000n^2 = O(n^5)
.. math:: 1000n^2 \ne \Omega(n^5)
.. math:: n^5 = O(2^n)
.. math:: 2*n^{10}+100*n^7+20*n^2 = \theta(n^{10})

Notations
~~~~~~~~~~
Since we can ignore constant factors, it is worthwhile to define the following notations:

- Notation
  :math:`f(n) = O(g(n))`:
  This notation means that there exists a constant k such that
  :math:`f(n) \le kg(n)`
  holds for all sufficiently large n.
  This notation is read as "f of n is big-O of g of n".
- Notation
  :math:`f(n) = \Omega (g(n))`:
  This holds if and only if
  :math:`g(n) = O(f(n))`
  holds, and is read as
  "f of n is Omega of g of n".
- Notation
  :math:`f(n) = \theta (g(n))`:
  This holds if and only if
  :math:`f(n) = O(g(n))` and :math:`f(n) = \Omega (g(n))`
  both hold, and is read as
  "f of n is Theta of g of n".
  
You can view these notations as analogous to the less than or equal to, greater than or equal to, and equals signs.
The following examples can help in better understanding these symbols.

.. math:: 1000n = O(0.00001n)
.. math:: 1000n = \Omega(0.00001n)
.. math:: 1000n = \theta(0.00001n)
.. math:: 1000n^2 = O(n^5)
.. math:: 1000n^2 \ne \Omega(n^5)
.. math:: n^5 = O(2^n)
.. math:: 2*n^{10}+100*n^7+20*n^2 = \theta(n^{10})

دسته بندی پیچیدگی های مهم
----------------------------

در مسائلی که ما بررسی می‌کنیم پیچیدگی هایی مرتبا تکرار می‌شوند که آن ها را در زیر
بررسی می‌کنیم.

Classification of Important Complexities
----------------------------------------

In the problems we examine, certain complexities are frequently repeated, which we will discuss below.

پیچیدگی خطی
~~~~~~~~~~~~~
به الگوریتمی که زمان اجرایش ضریبی از طول ورودی باشد، الگوریتم خطی می گوییم. اگر طول
ورودی n باشد زمان اجرای الگوریتم
.. math:: O(n)
است. در حالت عادی نمی توان الگوریتمی بهتر از الگوریتم خطی پیدا کرد زیرا خود دریافت
ورودی ضریبی از 
n
طول می‌کشد و حتی اگر زمان ورودی گرفتن را در نظر نگیریم چون در زمان ثابت می توان
روی تعداد ثابتی از متغیر ها و خانه های حافظه انجام داد پس برای این که تمام ورودی
را روی خروجی اثر دهیم باید ضریبی از طول ورودی را صرف کنیم.

Linear Complexity
~~~~~~~~~~~~~
An algorithm whose execution time is a constant multiple of the input size is called a linear algorithm. If the input
size is n, the algorithm's execution time is
.. math:: O(n)
In normal cases, one cannot find an algorithm better than a linear algorithm, because reading
the input itself takes a multiple of
n
time. Even if we don't consider input reading time, since operations can be performed on a constant number of variables and memory locations in constant time, to make all input affect the output, we must spend a multiple of the input size.

تابع لگاریتم
~~~~~~~~~~~~~~
تابع لگاریتم تابعی است که در تحلیل پیچیدگی الگوریتم ها بسیار ظاهر می‌شود.
این تابع به صورت معکوس تابع توان ۲ تعریف می‌شود. یعنی:
:math:`2^{lg(n)} = n`
به سادگی می توان صحت گزاره های زیر را بررسی کرد.

.. math:: lg(a*b) = lg(a) + lg(b)
.. math:: lg(a^b) = b * lg(a)
.. math:: a^{\frac{lg(n)}{lg(a)}} = n
.. math:: lg(n)^k = O(n)

Logarithm Function
~~~~~~~~~~~~~~
The logarithm function is a function that appears frequently in the analysis of algorithm complexity.
It is defined as the inverse of the power-of-2 function. That is:
:math:`2^{lg(n)} = n`
The correctness of the following statements can be easily verified.

.. math:: lg(a*b) = lg(a) + lg(b)
.. math:: lg(a^b) = b * lg(a)
.. math:: a^{\frac{lg(n)}{lg(a)}} = n
.. math:: lg(n)^k = O(n)

پیچدگی شبه خطی
~~~~~~~~~~~~~~~~
به الگوریتمی که زمان اجرایش از
:math:`O(n*lg(n)^k)`
باشد که k عددی ثابت است، این الگوریتم زمان اجرای شبه خطی دارد.

Quasilinear Complexity
~~~~~~~~~~~~~~~~
An algorithm whose execution time is
:math:`O(n*lg(n)^k)`,
where k is a constant, has quasilinear execution time.

پیچیدگی چندجمله ای
~~~~~~~~~~~~~~~~~~~~~~
اگر زمان اجرای الگوریتم از
:math:`O(n^k)`
باشد و k عددی ثابت باشد می گوییم زمان اجرای الگوریتم چند جمله ای است.

Polynomial Complexity
~~~~~~~~~~~~~~~~~~~~~~
If the algorithm's execution time is
:math:`O(n^k)`,
where k is a constant, we say the algorithm has polynomial execution time.

پیچیدگی نمایی
~~~~~~~~~~~~~~~
اگر زمان اجرای الگوریتم از
:math:`O(c^n)`
باشد و c عددی ثابت باشد می گوییم زمان اجرای الگوریتم نمایی است.
الگوریتم های نمایی عموما مناسب نیستند و برای
n
های بزرگ (مثلا ۱۰۰۰) می توانند به اندازه عمر کهکشان طول بشکند :))

Exponential Complexity
~~~~~~~~~~~~~~~
If the algorithm's execution time is
:math:`O(c^n)`,
where c is a constant, we say the algorithm has exponential execution time.
Exponential algorithms are generally not suitable and for
large n
(e.g., 1000) can take as long as the age of the galaxy :))