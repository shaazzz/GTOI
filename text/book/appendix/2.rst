آشنایی با الگوریتم ها و پیچیدگی
=================================

امروزه کامپیوتر ها بسیار سریع هستند، اما هیچ کامپیوتری دستورات را در لحظه اجرا نمی کند.
مقدار بسیار کوچکی از زمان طول می کشد که کامپیوتر یک دستور را اجرا کند. برای مثال کامپیوتر
های امروز در فرکانس حدود سه گیگاهرتز کار می کنند که یعنی یک زیر دستور العمل را در زمان
حدود سه دهم نانو ثانیه انجام می دهند که این یعنی هر دستور العمل در حدود چند نانو ثانیه
زمان می برد.

با این حال کار نوشتن برنامه ای که ساعت ها، یا حتی سال ها زمان ببرد، اصلا کار سختی
نیست. حتی ممکن است خودتان به آن برخورده باشید. مثلا در پردازش فیلم یا شبیه سازی های
فیزیکی ممکن است ساعت ها کامپیوتر خود را روشن گذاشته باشید تا پاسخ را دریافت کنید.

به همین دلیل در مسابقات برنامه نویسی محدودیت زمانی برای اجرای برنامه شما وجود دارد
و برنامه شما باید در زمانی حدود ۱ تا ۵ ثانیه
(بسته به مساله)
اجرا شود. به همین دلیل در هنگام طراحی الگوریتم ها محاسبه می کنیم که آیا راه ما
با توجه به شرایط ورودی در زمان خواسته شده اجرا می شود یا خیر و اگر اجرا می شد شروع
به پیاده سازی آن می کنیم.

تحلیل پیچیدگی
-------------------
سخت است که زمان اجرای یک برنامه را به طور دقیق حساب کنیم. برای مثال دستور


.. code-block:: cpp
  a[x] += a[y];

را در نظر بگیرید. این دستور چند عمل در سی پی یو است؟ پاسخ به این سوال بسیار سخت و نیازمند
شناخت دقیق کامپایلر و سی پی یو است. حتی ممکن است پاسخ این سوال بسته به نوع سی پی یو یا
کامپایلر یا درجه بهینه سازی کامپایلر یا مکان قرار گیری این دستور در کد فرق کند. برای مثال
خواندن y از حافظه، جمع x با a و خواندن خانه به دست آمده از حافظه یا جمع
مقدار a[x] و a[y] می تواند یک یا چند دستور العمل در سی پی یو باشد.

حتی اگر می دانستیم که برنامه ما از چند دستور العمل تشکیل شده، باز برای تخمین زمان اجرای
برنامه کافی نبود. برای مثال دستور باقیمانده و دستور شیفت بیتی هر دو یک دستور العمل
هستند اما باقیمانده بسیار بیشتر از شیفت بیتی طول می کشد.

بنابراین از محاسبه زمان دقیق اجرای کد صرف نظر می کنیم و تنها به این اکتفا می کنیم که
دستورات سی پی یو مانند خواندن از آرایه یا جمع دو عدد، مقدار ثابتی از زمان طول می کشند.
به همین صورت، دقت اندازه گیری ما در حد یک ضریب پایین می آید. برای مثال این کد را در نظر بگیرید


.. code-block:: cpp
  for (int i = 0; i < n; i++) {
    for (int j = 0; j < n; j++) {
      swap(a[i],a[j]);
    }
  }

ما نمی دانیم که تابع سوپ یا عمل مقایسه یا عمل پلاس پلاس هر کدام چند واحد زمانی طول می کشند
اما می دانیم که هر کدام مقدار ثابتی از زمان طول می کشند. پس می توان گفت که زمان اجرای این کد
:math:`kn^2`
است که k یک ضریب ثابت با واحد ثانیه است.
در عموم موارد مقدار k برای ما اهمیتی ندارد و از آن چشم پوشی می کنیم.

نماد ها
~~~~~~~~~~
چون می توانیم از ضریب چشم پوشی کنیم، تعریف نماد های زیر خالی از لطف نیست:

- نماد
  :math:`f(n) = O(g(n))`:
  این نماد به این این معنی است که ضریبی مانند k وجود دارد به طوری که
  :math:`f(n) \le kg(n)`
  به ازای تمامی n های بزرگ برقرار باشد.
  این نماد به صورت اِف اِن از او یِ جیِ اِن است خوانده می شود.
- نماد
  :math:`f(n) = \Omega (g(n))`:
  اگر و تنها اگر
  :math:`g(n) = O(f(n))`
  بر قرار باشد برقرار است و می خوانیم
  اِف اِن از اُمِگا یِ جیِ اِن است
- نماد
  :math:`f(n) = \theta (g(n))`:
  اگر و تنها اگر
  :math:`f(n) = O(g(n))` و :math:`f(n) = \Omega (g(n))`
  بر قرار باشد برقرار است و می خوانیم
  اِف اِن از تِتا یِ جیِ اِن است
  
به این نماد ها می توانید به چشم علامت های کوچکتر مساوی، بزرگتر مساوی و مساوی نگاه کنید.
مثال های زیر می تواند به درک بهتر این علامت ها کمک کند.

.. math:: 1000n = O(0.00001n)
.. math:: 1000n = \Omega(0.00001n)
.. math:: 1000n = \theta(0.00001n)
.. math:: 1000n^2 = O(n^5)
.. math:: 1000n^2 \ne \Omega(n^5)
.. math:: n^2 = O(2^n)
